{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/caddis/solution-using-pytorch-albumentation-mlflow?scriptVersionId=135842213\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Installs \n\n!pip install mlflow==1.30.1 dagshub==0.2.12 progressbar2==4.2.0 GPUtil==1.4.0 albumentations==1.3.0\n\n# Imports\n\nimport albumentations as A\nimport cv2\nfrom dataclasses import dataclass, asdict\nimport dagshub\nfrom GPUtil import showUtilization as gpu_usage\nimport matplotlib.pyplot as plt\nimport mlflow\nfrom numba import cuda\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom pprint import pprint\nimport progressbar\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau\nfrom torchvision import models, transforms, utils\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch import flatten\nfrom torchmetrics import MeanSquaredError\n\n# General utilities \n\ndef set_seeds():\n    torch.manual_seed(0)\n    np.random.seed(0)\n    torch.cuda.manual_seed(0)\n    torch.cuda.manual_seed_all(0)\n    torch.backends.cudnn.deterministic=True\n    \ndef free_gpu_cache():\n    print(\"Initial GPU usage\")\n    gpu_usage()                             \n\n    torch.cuda.empty_cache()\n    cuda.select_device(0)\n    cuda.close()\n    cuda.select_device(0)\n\n    print(\"GPU usage after emptying the cache\")\n    gpu_usage()","metadata":{"execution":{"iopub.status.busy":"2023-05-16T19:34:17.967686Z","iopub.execute_input":"2023-05-16T19:34:17.96875Z","iopub.status.idle":"2023-05-16T19:34:17.980555Z","shell.execute_reply.started":"2023-05-16T19:34:17.968694Z","shell.execute_reply":"2023-05-16T19:34:17.979521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set up\n\nset_seeds()\n\nDIR_PATH = \"/kaggle/input/facial-keypoints-detection/\"\ntraining_data = pd.read_csv(f\"{DIR_PATH}training.zip\")\ntest_data = pd.read_csv(f\"{DIR_PATH}test.zip\")\nid_lookup_table = pd.read_csv(f\"{DIR_PATH}IdLookupTable.csv\")\n\n@dataclass  \nclass ModelParams:\n    BATCH_SIZE: int = 64\n    VALID_SIZE: float = 0.1\n    N_EPOCHS: int = 180\n    IMG_SIZE: int = 96\n    OUTPUT_SIZE: int = 30 \n    S_OUTPUT_SIZE: int = 8\n    L_OUTPUT_SIZE: int = 22\n    LEARNING_RATE: float = 0.001\n\n# dagshub.init(\"facial_reg_model\", \"caddis90\", mlflow=True)\n# mlflow.set_tracking_uri('https://dagshub.com/caddis90/facial_reg_model.mlflow')\nmlflow.set_experiment(experiment_name=\"cnn\")\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using {device}\")\n\nl_dataset_cols = [\n    'left_eye_inner_corner_x','left_eye_inner_corner_y', 'left_eye_outer_corner_x',\n    'left_eye_outer_corner_y', 'right_eye_inner_corner_x','right_eye_inner_corner_y',\n    'right_eye_outer_corner_x','right_eye_outer_corner_y', 'left_eyebrow_inner_end_x',\n    'left_eyebrow_inner_end_y', 'left_eyebrow_outer_end_x','left_eyebrow_outer_end_y',\n    'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y', 'right_eyebrow_outer_end_x',\n    'right_eyebrow_outer_end_y', 'mouth_left_corner_x', 'mouth_left_corner_y',\n    'mouth_right_corner_x', 'mouth_right_corner_y', 'mouth_center_top_lip_x',\n    'mouth_center_top_lip_y', 'Image']\n\ns_dataset_cols = [\n    'left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x',\n    'right_eye_center_y','nose_tip_x', 'nose_tip_y',\n    'mouth_center_bottom_lip_x','mouth_center_bottom_lip_y','Image']\n\nl_dataset = training_data[l_dataset_cols]\ns_dataset = training_data[s_dataset_cols]","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:07:08.415125Z","iopub.execute_input":"2023-05-16T20:07:08.415506Z","iopub.status.idle":"2023-05-16T20:07:12.380441Z","shell.execute_reply.started":"2023-05-16T20:07:08.415477Z","shell.execute_reply":"2023-05-16T20:07:12.379414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data \n\nclass FacialKeypointsDataset(Dataset):\n    \n    def __init__(self, dataset, train=True, transform=None):\n        self.dataset = dataset\n        self.train = train\n        self.transform = transform\n\n    def get_image(self, idx):\n        image = np.fromstring(self.dataset.iloc[idx, -1], sep=' ', dtype = np.uint8)\n        image = image.astype(np.float32)\n        image = image.reshape(ModelParams.IMG_SIZE, ModelParams.IMG_SIZE, 1) \n        \n        return image\n        \n    def __len__(self):\n        return len(self.dataset)\n    \n    def __getitem__(self, idx):        \n        if self.train:\n            keypoints = self.dataset.iloc[idx, :-1].values.astype(np.float32)\n            total_keypoints = int(len(keypoints)/2)\n            keypoints = keypoints.reshape([total_keypoints, 2])\n        else:\n            keypoints = None\n        \n        if self.transform:\n            data_cols = self.dataset.columns.tolist()\n            sample = self.transform(\n                image=self.get_image(idx), \n                keypoints=keypoints, \n                class_labels=data_cols[0:-1])\n            sample[\"keypoints\"] = torch.tensor(list(sum(sample[\"keypoints\"], ()))).float()\n        else:\n            sample = {\"image\": self.get_image(idx)}\n            \n        sample[\"image\"] = torch.from_numpy(sample[\"image\"].transpose(2, 0, 1)).float()\n        sample[\"image\"] = sample[\"image\"] / 255\n        \n        return sample\n\ndef prepare_dataloaders(dataset, valid_size, batch_size):\n    dataset_len = len(dataset)\n    dataset_indices = list(range(dataset_len))\n    np.random.shuffle(dataset_indices)\n    split = int(np.floor(valid_size * dataset_len))\n    train_idx, valid_idx = dataset_indices[split:], dataset_indices[:split]\n    \n    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=SubsetRandomSampler(train_idx))\n    valid_loader = DataLoader(dataset, batch_size=batch_size, sampler=SubsetRandomSampler(valid_idx))\n    \n    return train_loader, valid_loader\n\n\n# Utilities\n\ndef show_image(image, training_key_points, test_key_points=[]):  \n    image = image.numpy().transpose(1, 2, 0)\n\n    plt.imshow(image, cmap=\"gray\")\n\n    total_keypoints = int(len(training_key_points)/2)\n    training_key_points = training_key_points.reshape([total_keypoints, 2])\n    plt.plot(training_key_points[:,0], training_key_points[:,1], 'gx')\n    \n    if len(test_key_points) > 0:        \n        test_key_points = test_key_points.reshape([total_keypoints, 2])\n        plt.plot(test_key_points[:,0], test_key_points[:,1], 'rx')\n\n        \ndef mask_output_and_target(output, target):\n    mask = torch.isnan(target)\n    return output[~mask], target[~mask]\n\ndef train(train_loader, valid_loader, model, optimizer, scheduler):\n    with mlflow.start_run():\n        mlflow.log_params(asdict(ModelParams()))\n        for epoch in progressbar.progressbar(range(ModelParams.N_EPOCHS)):\n            epoch_train_loss, epoch_valid_loss = 0.0, 0.0\n\n            model.train() \n            for i, batch in enumerate(train_loader):\n                optimizer.zero_grad()\n                output = model(batch['image'].to(device))\n                output_with_mask, target_with_mask = mask_output_and_target(\n                        output=output, \n                        target=batch['keypoints']\n                )\n                loss = criterion(output_with_mask, target_with_mask.to(device))\n                loss.backward()\n                optimizer.step()\n                epoch_train_loss += loss.item()*batch['image'].size(0)\n                batch_train_rmse = rmse(output_with_mask.cpu(), target_with_mask.cpu())\n\n            epoch_train_rmse = rmse.compute()\n            rmse.reset()\n\n            with torch.no_grad():\n                model.eval() \n                for i, batch in enumerate(valid_loader):\n                    output = model(batch['image'].to(device))\n                    output_with_mask, target_with_mask = mask_output_and_target(\n                            output=output, \n                        target=batch['keypoints']\n                    )\n                    loss = criterion(output_with_mask, target_with_mask.to(device))\n                    epoch_valid_loss += loss.item()*batch['image'].size(0)\n                    batch_valid_rmse = rmse(output_with_mask.cpu(), target_with_mask.cpu())\n\n                epoch_valid_rmse = rmse.compute()\n                rmse.reset()\n                epoch_train_loss = np.sqrt(epoch_train_loss/len(train_loader.sampler.indices))\n                epoch_valid_loss = np.sqrt(epoch_valid_loss/len(valid_loader.sampler.indices))\n                \n                mlflow.log_metric(\"train_loss\", epoch_train_loss, step=epoch)\n                mlflow.log_metric(\"valid_loss\", epoch_valid_loss, step=epoch)\n                mlflow.log_metric(\"train_rmse\", epoch_train_rmse, step=epoch)\n                mlflow.log_metric(\"valid_rmse\", epoch_valid_rmse, step=epoch)\n            \n            scheduler.step(metrics=epoch_valid_loss)\n            mlflow.log_metric(\"learning_rate\", optimizer.param_groups[0]['lr'], step=epoch)\n\n            \ndef predict(model, test_loader):    \n    model.eval()\n    with torch.no_grad():\n        for i, batch in progressbar.progressbar(enumerate(test_loader)):\n            output = model(batch['image'].to(device)).cpu().numpy()\n            output = np.clip(output, a_min=0, a_max=ModelParams.IMG_SIZE)\n            if i == 0:\n                test_predictions = output\n            else:\n                test_predictions = np.vstack((test_predictions, output))\n        \n    return test_predictions\n\ndef create_submission(predictions, prediction_features, id_lookup_table=id_lookup_table):\n    features = list(id_lookup_table['FeatureName'])\n    img_ids = list(id_lookup_table['ImageId']-1) \n\n    prediction_indices = [prediction_features.index(feature) for feature in features]\n\n    submission = pd.DataFrame({\n        \"RowId\": list(id_lookup_table['RowId']),\n        \"Location\": [predictions[x][y] for x, y in zip(img_ids, prediction_indices)]\n    })\n    submission.to_csv(\"submission.csv\",index = False)\n    print(\"Submission successful!\")\n       \n# Model\n\nl_resnet50 = models.resnet50(num_classes = ModelParams.L_OUTPUT_SIZE)\nl_resnet50.inplanes = ModelParams.IMG_SIZE\nl_resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n\ns_resnet50 = models.resnet50(num_classes = ModelParams.S_OUTPUT_SIZE)\ns_resnet50.inplanes = ModelParams.IMG_SIZE\ns_resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n\ntransformations = A.Compose([\n    A.Rotate(limit=15, border_mode=cv2.BORDER_CONSTANT, p=0.8),\n    A.Affine(p=0.2),\n#     A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, brightness_by_max=False, p=0.2),\n    A.OneOf([\n#             A.GaussNoise(p=0.8),\n#             A.RandomGamma(p=0.8),\n            A.Blur(blur_limit=3, p=0.8),\n            A.PixelDropout(p=0.8)\n        ], p=1.0),     \n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=0, p=0.2, border_mode=cv2.BORDER_CONSTANT),\n    ],\n    keypoint_params = A.KeypointParams(format = 'xy', remove_invisible=False)\n)\n\ns_trainset = FacialKeypointsDataset(s_dataset, transform=transformations)\nl_trainset = FacialKeypointsDataset(l_dataset, transform=transformations)\ntestset = FacialKeypointsDataset(test_data, train=False)\n\ns_train_loader, s_valid_loader = prepare_dataloaders(\n        s_trainset, \n        valid_size=ModelParams.VALID_SIZE, \n        batch_size=ModelParams.BATCH_SIZE\n)\nl_train_loader, l_valid_loader = prepare_dataloaders(\n        l_trainset, \n        valid_size=ModelParams.VALID_SIZE, \n        batch_size=ModelParams.BATCH_SIZE\n)\ntest_loader = DataLoader(testset, batch_size=ModelParams.BATCH_SIZE)\n\nl_model = l_resnet50\nl_model = l_model.to(device)\ns_model = s_resnet50\ns_model = s_model.to(device)\n\ncriterion = nn.MSELoss().to(device)\nrmse = MeanSquaredError(squared=False).to(device)\n\nl_optimizer = optim.Adam(l_model.parameters(), lr=ModelParams.LEARNING_RATE)\nl_scheduler = ReduceLROnPlateau(\n    optimizer=l_optimizer, \n    mode=\"min\", \n    factor=0.5,\n    patience=5,\n    min_lr=1e-15\n)\n\ns_optimizer = optim.Adam(s_model.parameters(), lr=ModelParams.LEARNING_RATE)\ns_scheduler = ReduceLROnPlateau(\n    optimizer=s_optimizer, \n    mode=\"min\", \n    factor=0.5,\n    patience=5,\n    min_lr=1e-15\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:09:14.057839Z","iopub.execute_input":"2023-05-16T20:09:14.058264Z","iopub.status.idle":"2023-05-16T20:09:14.895118Z","shell.execute_reply.started":"2023-05-16T20:09:14.058231Z","shell.execute_reply":"2023-05-16T20:09:14.894125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(\n    train_loader=l_train_loader, \n    valid_loader=l_valid_loader, \n    model=l_model, \n    optimizer=l_optimizer, \n    scheduler=l_scheduler\n)\n\ntrain(\n    train_loader=s_train_loader, \n    valid_loader=s_valid_loader, \n    model=s_model, \n    optimizer=s_optimizer, \n    scheduler=s_scheduler\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-16T20:09:18.400605Z","iopub.execute_input":"2023-05-16T20:09:18.401578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l_predictions = predict(model=l_model, test_loader=test_loader)\ns_predictions = predict(model=s_model, test_loader=test_loader)\npredictions = np.hstack((l_predictions, s_predictions))\nprediction_features = l_dataset_cols[:-1] + s_dataset_cols[:-1]\ncreate_submission(predictions=predictions, prediction_features=prediction_features)","metadata":{"execution":{"iopub.status.busy":"2023-05-14T18:45:42.106804Z","iopub.status.idle":"2023-05-14T18:45:42.107475Z","shell.execute_reply.started":"2023-05-14T18:45:42.107233Z","shell.execute_reply":"2023-05-14T18:45:42.107257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_sample = s_trainset[0]\n\ns_model.eval()\nwith torch.no_grad():\n    test_key_points = s_model(plot_sample['image'].unsqueeze(0).to(device)).cpu().numpy()\n\nshow_image(image=plot_sample['image'], training_key_points=plot_sample[\"keypoints\"].numpy(), test_key_points=test_key_points)\npprint(plot_sample[\"replay\"])","metadata":{"execution":{"iopub.status.busy":"2023-05-14T19:47:54.803143Z","iopub.execute_input":"2023-05-14T19:47:54.803512Z","iopub.status.idle":"2023-05-14T19:47:55.024032Z","shell.execute_reply.started":"2023-05-14T19:47:54.80348Z","shell.execute_reply":"2023-05-14T19:47:55.023087Z"},"trusted":true},"execution_count":null,"outputs":[]}]}